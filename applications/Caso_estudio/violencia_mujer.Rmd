---
title: "Procesamiento de Lenguaje Natural"
subtitle: "Caso de estudio: Violencia contra la Mujer"
author: Cristopher Aguirre Criollo
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_notebook:
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: true
      smooth_scroll: false
bibliography: biblio.bib
---

# **1. Contexto del Análisis**

## **1.2. Objetivo**

+ Analizar el contenido de las noticias relacionadas a **Violencia contra la mujer** de cinco períodicos ecuatorianos, con el fin de conocer el mensaje que transmiten los medios de comunicación dentro de la lucha contra la violencia de género. 

# **2. Mineo de texto**

## **2.1. Prerrequisitos**

Cargamos el conjunto de librería que vamos a utilizar dentro del análisis. A continuación se detalla es uso de cada una de ella:

```{r message=FALSE, warning=F}
#Librerias que se van a usar para todo el análisis
pckg <- c("easypackages","tidyverse","rvest","purrr","kable","tidytext")
# install.packages("pckg") desomentar en caso de no tener innstalados los paquetes
library(easypackages)
libraries(pckg)
```

## **2.2. Obtención de los datos**

La fuente de datos que se utilizó es Google News, donde se realizó web scraping (raspado web), para extraer información de las noticias relacionadas con el objetivo de análisis.  

```{r}
# Definición de funciones

## Función para el scrapeo de noticias en google news.

obtieneNoticiasBusqueda <-  function(busqueda){
  news_pag = "https://news.google.com/"
  parametro_busqueda = "search?q="
  busqueda_no_espacios = gsub(" ","%20", busqueda)
  parametro_final = "&hl=es-419&gl=US&ceid=US:es-419"
  html_dir = paste0(news_pag,parametro_busqueda,busqueda_no_espacios,parametro_final)
  google_news = read_html(html_dir)
  noticias = google_news %>% 
    html_nodes(css = ".xP6mwf") %>% 
    html_children()
  noticiasDF = map(noticias,obtieneNoticiasData)
  noticiasDF = bind_rows(noticiasDF)
  noticiasDF = noticiasDF[!is.na(noticiasDF$Titular),]
  return(noticiasDF)
}

## Función auxiliar para obtener características de la noticia.

obtieneNoticiasData = function(noticia){
  news_pag = "https://news.google.com/"
  titular = noticia %>% html_node("h3") %>% html_text()
  fecha = noticia %>% html_node("time") %>% html_attr("datetime")
  diario = noticia %>% html_node("a.wEwyrc.AVN2gc.uQIVzc.Sksgp") %>% html_text()
  link_enmascarado = noticia %>% html_node("h3 a") %>% html_attr("href")
  link_enmascarado = paste0(news_pag,substring(link_enmascarado,3))  
  link_leido = read_html(link_enmascarado)
  link = link_leido %>% 
    html_nodes(css='a') %>% 
    tail(1) %>% 
    html_attr("href")
  noticiaDF = data.frame(Titular=titular, Fecha=fecha, Diario=diario, Link=link, stringsAsFactors = F)
  return(noticiaDF)
}

```

**Obtener noticias sobre violencia contra a mujer en Ecuador**
```{r}
noticiasMujer <- obtieneNoticiasBusqueda("Violencia contra la mujer Ecuador")
```

Hata la fecha de corte los diarios ecuatorianos que más noticias relacionados con **la violencia contra la mujer** publicaron fueron los que se presentan a continuación: 

```{r}
noticiasMujer %>% count(Diario) %>% slice_max(order_by = n,n=5)
```

Para poder obtener la noticia completa se obtiene mediante el complemento de Google **inspector gadget** un diccionario de los CSS de cada uno de los diarios estudiados, el CSS es un lenguaje que define la apariencia de un documento. Posterior a esto, La función **obtenerNoticiaNacional** nos permitirá obtener la noticia completa que se encuentre dentro de los diccionarios CSS definidos previamente.

```{r}

# Diccionario CSS de los diarios

Diarios <-  c("El Comercio (Ecuador)", "El Telégrafo (por eliminar)", 
            "El Universo","La Hora (Ecuador)","Primicias")

Estructura = data.frame(Diario=Diarios)
Estructura$CSS = NA
Estructura$CSS[Estructura$Diario=='El Comercio (Ecuador)'] = '.paragraphs'
Estructura$CSS[Estructura$Diario=='El Telégrafo (por eliminar)'] = '.itemFullText'
Estructura$CSS[Estructura$Diario=='El Universo'] = '.field-name-body'
Estructura$CSS[Estructura$Diario=='La Hora (Ecuador)'] = '#contenedorGeneral'
Estructura$CSS[Estructura$Diario=='Primicias'] = '#entry-content-inarticle'


# Función para obtener la noticia completa. 

obtenerNoticiaNacional = function(link_noticia, diario, diccionario_css){
  
  noticia_leida = read_html(link_noticia)
  css = diccionario_css$CSS[diccionario_css$Diario==diario]
  
  text_nodes = noticia_leida %>% 
    html_nodes(css = css) %>% 
    html_nodes("p")
  
  text = text_nodes %>% 
    html_text()
  
  text = paste0(text, collapse = " ")
  
  return(text)
}
```

Para obtener la noticia completa se toma como input el dataframe de la busqueda realizada mediante web scraping, se filtra solo los 5 diarios que se van a tomar en cuenta dentro del análisis y se ejecuta la función que se definió para la extracción de todas las noticias. 

```{r}
noticiasMujer <-  noticiasMujer %>% filter(Diario %in% Diarios)
news = map2_chr(noticiasMujer$Link, noticiasMujer$Diario, obtenerNoticiaNacional, diccionario_css=Estructura)
noticiasMujer$Noticia = news
```

```{r}
head(noticiasMujer %>% select(Fecha, Diario, Titular, Link, Noticia))
```

El dataframe que nos da como resultado recoge: la fecha en que se publicó la noticia, el diario que la publicó, el titular, el link de acceso al sitio web donde se encuentra la noticia, y la noticia como tal. 


## **2.3. Limpieza de texto y tokenización**

Dentro del proceso de tokenización se a procedido a dividir un texto en las unidades que los conforman, para el caso de estudio se dividió en el elemento más sencillo, las palabras. Sin embargo, más adelante se busca realizar un análisis de n-gramas específicamente bigramas **(n=2)**.

Al momento de realizar la tokenización, se incumple el condición tidy de nuestro dataframe, ya que nuestro objeto de análisis son las noticias que antes de la tokenización se encontraban una en cada fila del dataframe, para poder cumplir con la estructura incial, se duplica cada elemento de las demás columnas las veces que sea necesario, al proceso descrito se lo conoce como expansión, y se lo realiza con la función **unnest_tokens** del paquete **tidytext**.

```{r}
tidy_Mujer <-  noticiasMujer %>% unnest_tokens(output = Token, input = Noticia)

tidy_Mujer %>% 
       select(Diario, Titular, Token) %>% 
       head()
```


















